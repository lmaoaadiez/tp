{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"As you have gone through the theory of Linear Regression,this notebook will help you visualize what is happening behing the scene in linear Regression for 1 Feature Vector. I have described how you can implement Linear Regression through the mathematical formula ( that is way faster) and through Gradient Descent. ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-29T12:39:27.187237Z","iopub.execute_input":"2023-04-29T12:39:27.187993Z","iopub.status.idle":"2023-04-29T12:39:27.219315Z","shell.execute_reply.started":"2023-04-29T12:39:27.187936Z","shell.execute_reply":"2023-04-29T12:39:27.218156Z"}}},{"cell_type":"markdown","source":"\n\n <span style=\"font-size:25px;\"> <font color='blue'><b> Importing important Libraries <hr></b></font> </span>","metadata":{}},{"cell_type":"code","source":"import numpy as np # Numpy can help make mathematical computations faster. \n#In case you wonder how fast it makes the computation, go ahead and try these using lists directly.","metadata":{"execution":{"iopub.status.busy":"2023-04-29T13:52:47.707808Z","iopub.execute_input":"2023-04-29T13:52:47.708267Z","iopub.status.idle":"2023-04-29T13:52:47.746212Z","shell.execute_reply.started":"2023-04-29T13:52:47.708225Z","shell.execute_reply":"2023-04-29T13:52:47.745244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:25px;\"> <font color='blue'><b> Creating an array with points of a Straight Line\n <hr></b></font> </span>","metadata":{}},{"cell_type":"code","source":"# I have created points of Line y = 10x + 5\n# Later, I will be predicting this line later.\n\nX = np.array([i for i in range(0,100)])\ny = np.array([i*10 + 5 for i in X])","metadata":{"execution":{"iopub.status.busy":"2023-04-29T13:52:51.628327Z","iopub.execute_input":"2023-04-29T13:52:51.629647Z","iopub.status.idle":"2023-04-29T13:52:51.636386Z","shell.execute_reply.started":"2023-04-29T13:52:51.629595Z","shell.execute_reply":"2023-04-29T13:52:51.634766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plot of X and y\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\n\n# Create the trace\ntrace = go.Scatter(x=X, y=y, mode='markers')\n\n# Create the layout\nlayout = go.Layout(title='Plot of X and y', xaxis=dict(title='X'), yaxis=dict(title='y'))\n\n# Combine the trace and layout\nfig = go.Figure(data=[trace], layout=layout)\n\n# Plot the graph\npyo.iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T13:52:55.052798Z","iopub.execute_input":"2023-04-29T13:52:55.053733Z","iopub.status.idle":"2023-04-29T13:52:56.879501Z","shell.execute_reply.started":"2023-04-29T13:52:55.053684Z","shell.execute_reply":"2023-04-29T13:52:56.878386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<span style=\"font-size:25px;\"> <font color='blue'><b> Using Mathematical Formula\n <hr></b></font> </span>\n","metadata":{}},{"cell_type":"markdown","source":"The mathematical interpretation is covered in [this ](https://towardsdatascience.com/linear-regression-from-scratch-cd0dee067f72)blog. Just have a look and make sure you understand the concepts behind.<br><b>Note: </b> Root mean square error (RMSE) is a metric for evaluating regression models. For now rmse is sufficient for evaluating the model as well and you may skip the R2 metric, covered in the blog, which will be covered later in the course.\n<script src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js\"></script>\n</head>\n<body>\n    <p>The formula for RMSE is:</p>\n    <p>$$\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}$$</p>\n    where, <p>$$ \\hat{y}_i \\ is \\ the \\ predicted \\ value \\ corresponding \\ to \\ X_i \\\\ and \\ y_i \\ is \\ the \\ real \\ value$$</p>\n</body>","metadata":{}},{"cell_type":"code","source":"##Implementaion through direct method. (Solution of Optimization Result)\n\n# Calculate the mean of the given sample space\n\nX_mean = np.mean(X) \ny_mean = np.mean(y)\n\nn = len(X)\n\nnumerator = 0\ndenominator = 0\nfor i in range(n):\n\n    numerator += (X[i] - X_mean) * (y[i] - y_mean) # Calculate difference between each point and mean\n    denominator += (X[i] - X_mean) ** 2 # Calculating the square of difference.\n\nb1 = numerator / denominator\nb0 = y_mean - (b1*X_mean)\n\nprint(b1,b0)\n\ny_pred_m = X*b1 + b0 ","metadata":{"execution":{"iopub.status.busy":"2023-04-29T13:53:02.714463Z","iopub.execute_input":"2023-04-29T13:53:02.714899Z","iopub.status.idle":"2023-04-29T13:53:02.725950Z","shell.execute_reply.started":"2023-04-29T13:53:02.714860Z","shell.execute_reply":"2023-04-29T13:53:02.724588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objs as go\nimport plotly.offline as pyo\n\n# Create the trace\ntrace = go.Scatter(x=X, y=y_pred_m, mode='markers')\n\n# Create the layout\nlayout = go.Layout(title='Plot of X and y', xaxis=dict(title='X'), yaxis=dict(title='y'))\n\n# Combine the trace and layout\nfig = go.Figure(data=[trace], layout=layout)\n\n# Plot the graph\npyo.iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T13:53:36.621637Z","iopub.execute_input":"2023-04-29T13:53:36.622077Z","iopub.status.idle":"2023-04-29T13:53:36.657715Z","shell.execute_reply.started":"2023-04-29T13:53:36.622036Z","shell.execute_reply":"2023-04-29T13:53:36.656597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:25px;\"> <font color='blue'><b> Implementation through Gradient Descent\n\n","metadata":{}},{"cell_type":"code","source":"## Implementation using Gradient Descent\n## Setting up the intial parameters\n\nweights = 0\nbias = 0\nalpha = 0.0001 ## Learning Rate\nepochs = 500000 \n## We will be converging the line as y = weights*X + bias\n\ndef prediction(weights,bias,X):\n     return weights*X + bias\n\ndef gradient(X,y,y_pred,n):\n    error = (1/n) * sum((y - y_pred) ** 2) ## This error is MSE \n    dw = (2/n) * sum((y - y_pred)*X) ## Partial derivative of error with respect to w, using y_pred = weights(w) * X + bias(b)\n    db = (2/n) * sum(y - y_pred) ## Partial derivative of error with respect to b, using y_pred = weights(w) * X + bias(b)\n    return -dw,-db\n\n\nfor i in range(epochs):\n    y_pred = prediction(weights,bias,X)\n    dw,db = gradient(X,y,y_pred,n)\n    weights = weights - alpha*dw ## Gradient Descent\n    bias = bias - alpha*db ## Gradient Descent\nprint(weights,bias)\ny_pred = X*weights + bias","metadata":{"execution":{"iopub.status.busy":"2023-04-29T13:53:43.668899Z","iopub.execute_input":"2023-04-29T13:53:43.669848Z","iopub.status.idle":"2023-04-29T13:54:06.761678Z","shell.execute_reply.started":"2023-04-29T13:53:43.669806Z","shell.execute_reply":"2023-04-29T13:54:06.760303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objs as go\nimport plotly.offline as pyo\n\n# Create the trace\ntrace = go.Scatter(x=X, y=y_pred, mode='markers')\n\n# Create the layout\nlayout = go.Layout(title='Plot of X and y', xaxis=dict(title='X'), yaxis=dict(title='y'))\n\n# Combine the trace and layout\nfig = go.Figure(data=[trace], layout=layout)\n\n# Plot the graph\npyo.iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T13:54:11.820934Z","iopub.execute_input":"2023-04-29T13:54:11.821789Z","iopub.status.idle":"2023-04-29T13:54:11.855220Z","shell.execute_reply.started":"2023-04-29T13:54:11.821747Z","shell.execute_reply":"2023-04-29T13:54:11.853891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:25px;\"> <font color='blue'><b> Making comparision of the three results.\n\n\nYou have seen that mathematical formula gave the exact result while gradient descent gave approximately correct result. Sometimes we have no other option but go for gradient descent. you will see these later in the course","metadata":{}},{"cell_type":"code","source":"# As you can expect, all the three lines will coincide\n# Create traces for each of the lines\ntrace1 = go.Scatter(x=X, y=y, mode='lines', name='Line 1')\ntrace2 = go.Scatter(x=X, y=y_pred_m, mode='lines', name='Line 2')\ntrace3 = go.Scatter(x=X, y=y_pred, mode='lines', name='Line 3')\n\n# Combine the traces and create the layout\ndata = [trace1, trace2, trace3]\nlayout = go.Layout(title='Plot of Three Lines', xaxis=dict(title='X'), yaxis=dict(title='Y'))\n\n# Create a figure and plot the graph\nfig = go.Figure(data=data, layout=layout)\npyo.iplot(fig)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-29T13:54:17.058872Z","iopub.execute_input":"2023-04-29T13:54:17.059703Z","iopub.status.idle":"2023-04-29T13:54:17.109486Z","shell.execute_reply.started":"2023-04-29T13:54:17.059649Z","shell.execute_reply":"2023-04-29T13:54:17.108036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}